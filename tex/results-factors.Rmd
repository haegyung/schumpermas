---
title: "Results: Baseline"
author: "Maximilian Held"
output: pdf_document
library: held_library.bib
---

# Administration

```{r administration, child='../keyneson/keyneson.wiki/q-administration.md'}
```
<!-- TODO MH: paste condition of instruction? -->
<!-- TODO MH include data-gathering here, too -->

<!-- COMMENT MH
notice: there may be stuff in the data that suggests how many factors make sense (loc 2287)
notice: I am definetely doing exploratory factor analysis; no ex-ante reason to expect one or the other result
make a correlation matrix, just for descriptives, look at which items are most highly correlated
same thing for q sorts
check kline 1994 and Harman 1976 in the above on PCA vs CFA
Harman 1976 says they will mostly be the same!
what we're loosing when then R2 increases is, by definition, some residuals.
interesting idea: maybe look at what kind of residuals was lost? could we tell a story about that?
-->

<!-- COMMENT MH
consider jonathan haidt, joshua greene on deep pragmatism and slow/fast morality
-->


# Data Import

All citizens as well as the researcher and the two moderators completed two Q sorts each, one at the beginning and one at the end of the conference.
<!-- TODO MH: see timetable -->

```{r import-q-sorts}
q_sorts <- import.q.sorts(
  q.sorts.dir = "keyneson/qsorts/",
  q.set = q_set,
  q.distribution = q_distribution,
  conditions = c("before","after"),
  manual.lookup = as.matrix(
    read.csv(
      "keyneson/keyneson-sample/keyneson-concourse/ids.csv",
      row.names=2
    )
  )
)
```

```{r import-q-feedback}
q_feedback <- import.q.feedback(
  q.feedback.dir = "keyneson/feedback/",
  q.sorts = q_sorts,
  q.set = q_set,
  manual.lookup = as.matrix(
    read.csv(
      "keyneson/keyneson-sample/keyneson-concourse/ids.csv",
      row.names=2
    )
  )
)
```

complete import of `r ncol(q_sorts)`, three participants


### Data Gathered

- 2x 18x Q-Sorts (before, after): cleaned
- 2x 18x Item Feedback (before, after): cleaned
- 17x Socio-Economic \& Demographic data: pending
- 15x General written feedback: cleaned
- 315x Notes, Posters, Illustrations: raw
- 1601x Photos
- 100hrs Audio: raw
- 80hrs Video (1080p): raw


## Participant Feedback


## Missing Data

```{r dropped-participants}
q_sorts <- q_sorts[ , !colnames(q_sorts) == "Wolfgang", ]  # delete researcher
q_sorts <- q_sorts[ , !colnames(q_sorts) == "Uwe", ]  # incomplete
q_sorts <- q_sorts[ , !colnames(q_sorts) == "Claus", ]  # incomplete
q_feedback <- q_feedback[ , !colnames(q_feedback) == "Wolfgang", ]  # delete researcher
q_feedback <- q_feedback[ , !colnames(q_feedback) == "Uwe", ]  # incomplete
q_feedback <- q_feedback[ , !colnames(q_feedback) == "Claus", ]  # incomplete
```

# Descriptives

```{r descriptives}
# item.mean <- apply(q.sorts, c(1,3), mean, na.rm = TRUE)
# item.mean <- cbind(item.mean, item.mean[,"after"] - item.mean[,"before"])
# colnames(item.mean)[3] <- "change"
# item.mean
# item.mean[order(item.mean[,"change"]),] #  sort by change

# item.sd <- apply(q.sorts, c(1,3), sd, na.rm = TRUE)
# item.sd <- cbind(item.sd, item.sd[,"after"] - item.sd[,"before"])
# colnames(item.sd)[3] <- "change"
# item.sd[order(item.sd[,"change"]),] #  sort
# item.sd

# person.cor <- cor(q.sorts[,,"before"])
# person.cor[which.min(abs(person.cor))]
# person.cor
# str(person.cor)
# help(which.min)
```

# Q Method Analysis

What kind of Q Methodological Analysis should I run?

- Deductive vs. inductive vs. abductive
- Theoretical / judgmental vs. objective
- Conservative vs. adventurous
- Holistic vs. atomized
- Baseline vs. treatment effect


What Software?

- SPSS / STATA: underspecialized (item scores, flagging, datamatrix)
- PQMethod: closed/obscure source (FORTRAN), unreliable?
- R / qmethod: open, versatile, difficult



```{r how many factors?}
library(paran)
hornvectors <- paran(t(q.sorts[,,"after"]),
			iterations = 1000,
			centile = 95,
			quietly = FALSE,
			status = TRUE,
			graph = TRUE,
			color = TRUE)
```

<!-- COMMENT MH
read kline 1994 on wattss/stenner on PCA vs CFA, and they will be similar as per harman1976
-->
<!-- COMMENT MH
check whether the two flagging criteria make sense, aren't they too restrictive?
-->

<!-- COMMENT MH
via qlist Since Mary Furnari decided to rely on varimax rotation, Watts & Stenner (2012), for instance, would actually recommend PCA. (But note that Watts & Stenner erroneously think that varimax maximizes the amount of explained variance. To clarify: Varimax searches a simple structure solution characterized by a maximal number of either high or near zero loadings for every factor which is arrived at by maximizing the variance of the factors' loadings. The amount of explained variance is not affected by rotation.)
In my view, the meaningfulness of certain quantitative coefficients in Q, like so-called 'significance' of factor loadings is often overrated. So as if observing coefficient based rules could provide mathematical-statistical  proof for the soundness of the researcher's decisions and conclusions. Without referring to the wisdom of inferential statistics (which is not applicable in Q, IMO), however, I would dare to bet that given 60% explained variance of the 1st factor and 4% and less for the following, that Mary Furnari won't be able to assemble groups of sorts (to be flagged on different factors) that represent distinct = uncorrelated views. But that's just a bet which I possibly can lose. So nothing is lost by just trying out varimax solutions with 2, 3, 4 ... factors. Two simple (but not 100% unambiguous) rules for accepting a factor solution: (1) At least 2, better 3, defining sorts (load strongly on the respective factor only). (2) Intercorrelations of factor scores at a moderate level (possible choice of critical level: not higher than the size of the loading accepted for a defining sort).
-->

```{r analysis}
keyneson <- list("before"=c(), "after"=c())
keyneson$before <- qmethod(
  dataset = q.sorts[,,"before"],
  nfactors = 3,
  rotation = "varimax",
  forced = TRUE
)
keyneson$after <- qmethod(
  dataset = q.sorts[,,"after"],
  nfactors = 3,
  rotation = "varimax",
  forced = TRUE
)
```

```{r call viz}
arrayviz <- array.viz(
  QmethodRes = keyneson$before
  ,f.names = c("resentment","critical","moderate")
  ,incl.qdc = TRUE
  ,color.scheme = "Set1"
  ,extreme.labels = c("very much disagree","very much agree")
)
arrayviz[3]
```

<!--
stephenson on number of factors, via verena
OS-9-3-Stephenson.pdf S. 89 â€œSecond, a little simple factor analysis is
all that the operations demand: It will be the end
% of work in this domain if anyone thinks that its be- all and end-all is factor analysis. The less of it, the better. Three or four factors are all that most well planned studies require; there's something loose in the works if anything like ten or so factors are carved out for interpretation. The key to sound work, i.e., to make discoveries, is what one puts into Q method as abduction, not what factor analysis turns out deductively.
-->

<!-- worry about bipolar factors -->

<!--
notice that I look at sd of pop, not sample, because it's not r stats
but still, dispersion is interesting - those are the loose lego blocks
is there maybe a need to also look at the loose lego blocks *overall*? And what are those? What are the loosest blocks?
-->

<!--
Frank destroys the SD of pro-socialism
-->

```{r frank discussion pro socialism}
q.feedback["pro-socialism","Frank","after"]
```

```{r add-type}
array.viz.data <- merge(  # add type of item
  x = array.viz.data
  ,y = q.sampling.structure  # that is where the types are from
  ,by.x = 0  # these are rownames
  ,by.y = "handle"  # that is how they are called
  ,all = TRUE
)
rownames(array.viz.data) <- array.viz.data$Row.names  # restore rownames
g <- g + geom_text(
  aes(
    ,fontface=c("plain","bold","italic")[metaconsensus]
  )
  ,size = 3.5
)
#g <- g + scale_family_manual(c("serif","sans","mono"))
```

## Factor Extraction

<!-- COMMENT MH
agree that in fact, as Kampen and Tamas point out, the representativeness of the q sample to the universe of statements is a weak, weak spot.
Important: as cuppen in  kampen and tamas writes 3112 it's not the number of supporters that count, just the perspectives.
Consider the discussion of q methodology and validities oin kampen tamas 3112
do cluster analysis instead of factor; according to kampen and tamas. This might be interesting.
-->


### Which Data Reduction Technique

<!--
factor extraction
just use factanal normal factor
or normal princcop as opposed to psych
http://www.statmethods.net/advstats/factor.html
http://cran.r-project.org/web/packages/nFactors/index.html
http://cran.r-project.org/web/packages/FactoMineR/index.html
psych also appears to do parallel analysis by fa.parallel
-->

- *Exploratory* Factor Analysis (Centroid) @Brown1980's favorite
- Principal Components Analysis
- ...?


### How many factors?

- Experience / Common sense: 6--8 persons per ex-ante factor (Stenner \& Watts 2012: loc 2652):
    \Sexpr{ncol(q.sorts)/8} factors
- Magic Number 7 (Brown 1980: 223):
    \Sexpr{ncol(q.sorts)/7} people per factor?!
- Eigenvalue of nth factor $>$ 1 (Kaiser 1960, Guttman 1954)
- Two or more loadings (Brown 1980: 222)
- Humphrey's rule: Cross-Product of 2 highest loadings greater than twice the standard error
- Scree plot (2nd derivative < 0)
- Parallel Analysis (Horn 1965)


<!-- look at communality -->

<!-- \cite[6]{Exel2005} recommends 4-5 people per viewpoint, which given 17 participants yields 3-4 factors, or viewpoints. -->

<!-- \cite{Wittenborn} says explicitly what the problem is: 132, namely that there is no test as to whether there are other people who would sort like this. -->


### What Rotation?

- Judgmental / Manual
- Automatic (varimax, equamax etc.)